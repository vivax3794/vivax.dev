# Compiler part 1 - How to generate an exe?

So in this little series, I am going to be making a compiler and taking you along every step of the way!

To be clear, this won't be a tutorial per se, but I will show you every step along the way.

Also, I am not a professional compiler dev, this is a hobby and from my own experience.

And if you want a better resource for making languages, check out [Crafting Interpreters](https://craftinginterpreters.com/), it is free online and goes over making an interpreter in huge detail. And yes I will make a compiler, but a lot of the concepts carry over, so if you ever get confused by this blog might try giving that a read;

Also having an understanding of Rust or C will help a lot in understanding some of the terms used (like pointer), I will try to explain stuff that isn't commonly known. 

### The goal

We are going to make a compiler in Rust, the lang will be simple with type inference!
Starting out with just numbers, then moving on to strings and even custom structs and classes.
Figure out how to make import systems, parse code into an AST (abstract syntax tree), how to resolve type information.

And most importantly how to generate LLVM IR and turn it into an exe that you can run independently.

We will also look a bit at how to create a good CLI interface for our compiler and how to handle errors. 
Another issue that comes up is testing, if you aren't writing tests for your code you should! Although what is the best way to test a compiler? Well, what I will be doing is adding `assert` statements to our language and running a bunch of smaller programs to see if they fail.

The lang itself is gonna be inspired by Python and Rust! Hence type inference, which means you won't have to declare the types of variables.
But arguments and return types you need to. an example of code in the lang might be:
```
fn add(a: int, b: int) -> int {
    return a + b;
}

fn main() {
    print add(1, 2);
}
```

and yes `print` is gonna be a statement as it makes debugging easier at the start before we have functions! 

### Assembly

So how do we create an exe? Well, we could write all the bytes manually ourselves! But that is a lot of work and most importantly isn't cross-platform :O
Because each CPU is gonna have a separate set of assembly instructions, and even on the same CPU model different OSes are going to have different exe formats!

So what do we do? Well, we use LLVM IR.

### LLVM

So what is this magical LLVM IR I speak of? Well, it is a programming lang, well an IR (Intermediate Representation), basically, it is somewhere between assembly and a programming lang. Most langs are converted into some form of IR before then being compiled all the way down to an exe.
Many compilers also have a lang specific IR that they use before converting to the LLVM IR, and we are going to as well.

And we don't need to generate the LLVM IR text ourselves, there are tools to do it for us making it really convenient! We will be using [`inkwell`](https://github.com/TheDan64/inkwell) for this, it wraps the LLVM C library.

### Overall compiler structure

This is how we are going to structure our compiler, and over the following blog posts we will work on these parts!

[![](https://mermaid.ink/img/pako:eNpNjrsOgzAMRX8l8kz6ARkqVWJBokuLOmWxwBTUPFBwBAjx7w3QoZ6uj4-lu0LtGwIFrfFT3WFgUeXaiTQVzSykvIrbyCdJIQFRLQOJQKM3kXvvDqdwTMGhkUU43T-w__TuM5Exh1uWr7ssHqf3W47DhWaCDCwFi32TSq27o4E7sqRBpdhQi9GwBu22pGJk_1xcDYpDpAzi0CBT3uM7oAXVohlp-wJr-kfl?type=png)](https://mermaid.live/edit#pako:eNpNjrsOgzAMRX8l8kz6ARkqVWJBokuLOmWxwBTUPFBwBAjx7w3QoZ6uj4-lu0LtGwIFrfFT3WFgUeXaiTQVzSykvIrbyCdJIQFRLQOJQKM3kXvvDqdwTMGhkUU43T-w__TuM5Exh1uWr7ssHqf3W47DhWaCDCwFi32TSq27o4E7sqRBpdhQi9GwBu22pGJk_1xcDYpDpAzi0CBT3uM7oAXVohlp-wJr-kfl)

## So let's write some code!

let's just start very simple, we will hardcode some inkwell code to generate a simple "Hello World" script, in the next post we will start laying out the code structure of our compiler!

### Installing inkwell and LLVM

> ***WARNING: ***
>
> This step takes a while, the first few steps are slow but you can sit thru them fine.
>
> The last build step on the other hand takes a VERY long time, so go watch a movie or something.
>
> The LLVM install below is building from source, it is what I found worked for me, but you should try your package managers LLVM first and if it works then great! you saved yourself a lot of time :D

first, we need to add the inkwell library to our project.
```bash
cargo add inkwell --features llvm15-0
```

now if you try to just run the code you get an error complaining that LLVM is not installed on your system (or maybe you don't in that case skip this step!)
You need to install LLVM, I am using Arch so will include instructions for that, but this should work on other Linux systems as well.

We will use [`llvmenv`](https://crates.io/crates/llvmenv) to build a local copy of the LLVM source code!
```bash
cargo install llvmenv
llvmenv init
```

We will need to clone the LLVM project and switch to the version 15 branch (this is around a 2GB download)
```bash
git clone https://github.com/llvm/llvm-project.git
cd llvm-project
git checkout release/15.x
```

then we will need to add this path to the list of LLVM versions `llvmenv` knows about, open the `llvmenv` entires file located in `~/.config/llvmend/entry.toml`.
```toml
[local-15]
path = "PATH_TO_YOUR_CLONED_REPO/llvm-project/llvm"
target = ["X86"]
``` 

Remember to specify where you cloned it, for example for me it is `/home/vivax/llvm-project/llvm` (I just cloned it in my home folder).
also, you might need a different value for `target`, look at what it says for `llvm-mirror`.

now when we do `llvmenv entries` we should see our `local-15` on there, and now we can build it!

This is going to take a good while, for me it took an hour.
```bash
llvmenv build-entry local-15
```
Now we need to tell cargo where to find our new LLVM build, llvmenv would likely have installed it in `~/.local/share/llvmenv/local-15`.
We can tell Rust how to find this using the `LLVM_SYS_150_PREFIX.` env var, you can either export it once:
```bash
export LLVM_SYS_150_PREFIX="/home/USERNAME/.local/share/llvmenv/local-15"
```

Alternatively you can save this in a file so cargo always uses it for this project (although that does make it hard to share the project with others, so be warned)

create a `.cargo` folder in the root of your project, then add a `config.toml` file in the folder.
```
.cargo/
    config.toml
src/
    ...
Cargo.toml
```
in the file we can set build settings
```toml
[env]
LLVM_SYS_150_PREFIX="/home/USERNAME/.local/share/llvmenv/local-15"
```
that way you don't have to export the path again each time you come back to the project!

Now that we got that installed, we can try to run our project again, (you might wanna do `cargo clean` first if you tried to build it earlier)

### Hello World

Okay, that was a lot of work (and time) for the first step :P
But now we can finally write some code! 

So we are just gonna do this in `main.rs` as a proof of concept, in the next post we will write a proper code structure with minimal implementations for each part of the compiler, and after that, we will have a technically fully working compiler, although it will be quite minimal. We will also tackle the CLI interface in the next post, so for now lets us just hardcode everything.

But first, we need to talk about lib-c, the standard library of C, we will be using it as well! You may ask, why are we using the stdlib from another lang, well simple, everybody is! The reason is that libc is implemented on basically any major platform you can imagine, and instead of dealing with OS specific terminal stuff, you can just use `printf` from libc!

first, we need some imports:
```
use inkwell::{context::Context, AddressSpace};
```

now let's get started, we need to create some structs we will use to generate our code.
```rust
let context = Context::create();
let module = context.create_module("hello world");
let builder = context.create_builder();
```

* the `context` is basically a builder for generic stuff like types.
* `module` is what will contain our definitions and code, think of it as a file!
* `builder` is what we use to generate code, we need to point it to the correct spot in the module, and we will get to that soon!

first let's declare some types we will be using later
```rust
let i8_type = context.i8_type();
let i8_ptr_type = i8_type.ptr_type(AddressSpace::default());
let i32_type = context.i32_type();
```
We are going to use an `i8`, `i32`, and also a `i8` pointer.
The `AddressSpace` is basically just where in memory the pointer points to, we don't really have any specific requirements for this so the `::default()` is fine.

So I mentioned we are going to use `printf`, but we need to tell LLVM what the hell `printf` is! When you are linking everything together there is no real concept of scope (except functions), all functions are in the same scope. so when we link with libc we get every function from libc in the global scope, but we need to declare what their types are as LLVM doesn't actually care about what libc is (with one exception, it does do optimizations around malloc/free).

```rust
let printf_type = i32_type.fn_type(&[i8_ptr_type.into()], true);
let printf = module.add_function("printf", printf_type, None);
```
so let's break this down, `printf_type` is basically the function signature, and what that line is saying is basically:
* The first parameter is an `i8` pointer, which is actually a string, a string is really just an array of characters, or `u8` (but we don't have unsigned types in LLVM, so `i8` it is)
* It then takes a variable amount of arguments, that is what the `true` is signaling.
* It then returns an `i32`, which is rarely used, but represents how many chars were written, or a negative number for error.

then we add the function declaration to the module, under the name `printf`, using the type we defined in the line above, the `None` is the linking option, for which we just leave it at default.

Have you ever wondered why basically every lang uses `main`? well, there is a reason! Did you know that the actual entry point to your program isn't `main`? it is `_start`? libc defines a `_start` function for us, it does some setup like reading arguments, then it calls `main()` and then calls `exit()` with mains return code!
So if you wanted to create a lang without libc (like if you are targeting embedded systems) you need to define `_start` instead!
But that is just some trivia for you, we are using libc, so we will define a `main()` function.

```rust
let main_function_type = i8_type.fn_type(&[], false);
let main_function = module.add_function("main", main_function_type, None);
```
this is very similar to `printf`, our return type is an `i8`, which will be the program's exit code, and we take no arguments.
now we can start generating our code!

```rust
let main_block = context.append_basic_block(main_function, "entry");
builder.position_at_end(main_block);
```

So a block is basically a part of code, a jump target if you will, these blocks are what you can use `goto`/`jump` to jump to.
They are how we structure `if`, loops, `switch`, etc. basically any form of branching/repeating code. We only need one block, the name doesn't really matter, all it does is help with debugging and reading the produced IR. But I would still recommend giving stuff good names for your own sake.

Then we move the `builder` to the end of the (empty) block, this means when we use the builder methods the code will be generated in this block! 

```rust
let string = builder.build_global_string_ptr("Hello World!", "output");
let string = string.as_pointer_value();
```

here we create a global string, basically a `const` and then convert it to a pointer (`i8*`), next we will construct the `printf` call. And again, the name doesn't matter!

```rust
builder.build_call(printf, &[string.into()], "Print_Statement");
```

This is very straightforward, we specify the function we wish to call, its arguments, and the name of the return value.
Now our code is basically done except, for one thing, our `main()` should return the exit code! 

```rust
builder.build_return(Some(&i8_type.const_int(0, false)));
```
We create a `const` int of value 0 (meaning no errors), don't worry about the `false` it is to enable a feature we don't need.

And now our code is finally done, we just need to save it! 

```rust
module.print_to_file("output.ll").unwrap();
```

Our code should now look like this: 
```rust
use inkwell::{context::Context, AddressSpace};

fn main() {
    let context = Context::create();
    let module = context.create_module("hello world");
    let builder = context.create_builder();

    let i8_type = context.i8_type();
    let i8_ptr_type = i8_type.ptr_type(AddressSpace::default());
    let i32_type = context.i32_type();

    let printf_type = i32_type.fn_type(&[i8_ptr_type.into()], true);
    let printf = module.add_function("printf", printf_type, None);

    let main_function_type = i8_type.fn_type(&[], false);
    let main_function = module.add_function("main", main_function_type, None);

    let main_block = context.append_basic_block(main_function, "entry");
    builder.position_at_end(main_block);

    let string = builder.build_global_string_ptr("Hello World!", "output");
    let string = string.as_pointer_value();
    builder.build_call(printf, &[string.into()], "Print_Statement");

    builder.build_return(Some(&i8_type.const_int(0, false)));

    module.print_to_file("output.ll").unwrap();
}
```

### Testing our work

If we now run this code we should get a `output.ll` file in our output directory,  it should look something like this:
```
; ModuleID = 'hello world'
source_filename = "hello world"

@output = private unnamed_addr constant [13 x i8] c"Hello World!\00", align 1

declare i32 @printf(ptr, ...)

define i8 @main() {
entry:
  %Print_Statement = call i32 (ptr, ...) @printf(ptr @output)
  ret i8 0
}
```
> if you are a VScode user you can use the following extension to get this syntax highligthed: <https://marketplace.visualstudio.com/items?itemName=colejcummins.llvm-syntax-highlighting>

Now we can try to run this directly using LLVMs builtin interpreter, it is nice for quick testing!
You might need to add the LLVM bin directory to your path.
```bash
export PATH=/home/USERNAME/.local/share/llvmenv/local-15/bin/:$PATH
lli output.ll
```

You should see "Hello World" being printed on your terminal!
But this is a compiler, so let's make this into a binary, in the next post these steps will be added to your compiler itself!

```bash
llc output.ll -filetype=obj -o output.o
```
This will use the LLVM static compiler to compile your IR to an object file. An object file is basically almost a binary, it contains the assembly/machine code, but also symbol data, our code is converted into one object file, then a lot of object files are combined into one binary. This is how dependencies are added to your projects, it is also common to have each code file produce its own object file, it makes structuring the compiler easier. But ofc one issue we can run into is that we might have module scope with functions separated, but object files don't, so we need to handle that, but that is a future problem.

Then we can use `clang`/`gcc` to compile the object file into a binary
```bash
clang output.o -no-pie -o output
```
This will use `clang` (`or gcc`) to convert your object file to a final binary, `clang` and `gcc` include libc by default so we don't have to worry about that. We also need to pass the `-no-pie` flag as the code we generate is not compatible with PIE binaries, because it uses absolute addresses.

We should now be able to run our binary!
```bash
./output
```
and we should see the "Hello World" message!

## Conclusion

If you followed along then congratulations! You now have a very hardcoded compiler, but you generated a binary from scratch! 
In the next post we will start laying out the code components of the compiler and start generting binaries based on a input script file :O 

If you have any questions feel free to leave them in the comments :D 
