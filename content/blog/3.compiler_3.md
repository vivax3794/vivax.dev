# Compiler part 2.2 - Type analysis and Code geneation!

So in the last blog post, we created the `parsing` module that generated our AST! Today we will be generating the internal IR, code generation (what we did in part 1, but now based on our IR!), and then also adding those shell commands we used afterward to the compiler itself.

> The full code for this post can be found at <https://github.com/vivax3794/viv_script_blog/tree/0a4be49ac325d2275b3352b36f94f91bbb2030f6>

## Type analysis

This step is basically "figure out what everything is!", we basically apply a bunch of rules to give every part of our compiler a type :D

This might sound hard, but it is rather simple, code might be something along the lines of
```rust
if plus.left == int a&& plus.right == int {plus.result = int}
else {error(...)}
```

### Ir

Our IR will contain type information in contrast to the AST, we could encode this using fields (and we will for dynamic types like structs.). While the AST represents what the code looks like, the IR should represent what the code *does*. so instead of just `add`, we will have `AddInt`, `AddFloat`, etc, etc.

```rust
/// ir.rs

#[derive(Debug)]
pub struct Module(pub Vec<Statement>);

#[derive(Debug)]
pub enum Statement {
    Print(PrintStatement),
}

#[derive(Debug)]
pub enum PrintStatement {
    Int(IntExpression),
}

#[derive(Debug)]
pub enum IntExpression {
    Literal(i32),
}
```

This also gives us a benefit from the rust compiler, We can't for example construct an `Int` type print and give it a String by accident! 
This ensures we do the type analysis correctly.

### Resolving Types

Now we can do some type analyzing, with so few instructions it is rather simple:
```rust
// type_analyzer.rs
use crate::ir;

enum TypedExpression {
    Int(ir::IntExpression),
}

impl TypedExpression {
    fn is_int(&self) -> bool {
        match self {
            TypedExpression::Int(_) => true,
        }
    }
}

#[derive(Debug, Error)]
#[error("Type error: {0}")]
struct TypeError(String);
```

So why this enum? Well consider `resolve_expression`, we don't know what the type should be when we walk an expression, so what is the return type? This is one of those times you would want a union, but in Rust, we shall use more enums!

Now for the analyzing!

```rust
fn resolve_literal(literal: &ast::Literal) -> anyhow::Result<TypedExpression> {
    match literal {
        ast::Literal::Integer(int) => Ok(TypedExpression::Int(ir::IntExpression::Literal(*int))),
    }
}

fn resolve_expression(expression: &ast::Expression) -> anyhow::Result<TypedExpression> {
    match expression {
        ast::Expression::Literal(literal) => resolve_literal(literal),
    }
}
```

Again here we use the power of abstraction! Very simple so far, but even with more complex rules this will stay simple :D 

```rust
fn resolve_print_statement(expression: &ast::Expression) -> anyhow::Result<ir::PrintStatement> {
    let typed_expression = resolve_expression(expression)?;

    match typed_expression {
        TypedExpression::Int(int_expression) => Ok(ir::PrintStatement::Int(int_expression)),
    }
}

fn resolve_statement(statement: &ast::Statement) -> anyhow::Result<ir::Statement> {
    match statement {
        ast::Statement::Print(expression) => {
            let print_statement = resolve_print_statement(expression)?;

            Ok(ir::Statement::Print(print_statement))
        }
    }
}

pub fn resolve_module(module: &ast::Module) -> anyhow::Result<ir::Module> {
    let mut ir_statements = Vec::new();

    for statement in &module.0 {
        let ir_statement = resolve_statement(statement)?;

        ir_statements.push(ir_statement);
    }

    Ok(ir::Module(ir_statements))
}
```

This should also be really clear, and a bit similar to the parsing. And in a way, we are just "parsing" the AST into an IR.
Now that we have this let's try to print it out!

```rust
// lib.rs

pub fn build(file_name: &str, options: CompilerOptions) -> anyhow::Result<()> {
    let code = std::fs::read_to_string(file_name).context("Reading input file")?;

    let ast = parsing::parse(&code, &options).context("Parsing input file")?;
    let ir = type_analyzer::resolve_module(&ast).context("Resolving types")?;

    if options.output_ir {
        println!("{ir:#?}");
    }

    Ok(())
}
```

Running our code now, `cargo run -- run test.viv --output-ir` you should get something like the following:
```rust
Module(
    [
        Print(
            Int(
                Literal(
                    1,
                ),
            ),
        ),
        Print(
            Int(
                Literal(
                    2,
                ),
            ),
        ),
    ],
)
```

## Code generation

Now we are gonna turn this IR into some actual code! Using `inkwell` the same way we did in Part 1.

### Generating LLVM IR

```rust
use inkwell::context::Context;

pub struct CodeGen<'ctx> {
    context: &'ctx Context,
    module: inkwell::module::Module<'ctx>,
    builder: inkwell::builder::Builder<'ctx>,
    fpm: inkwell::passes::PassManager<inkwell::module::Module<'ctx>>,
}

impl<'ctx> CodeGen<'ctx> {
    pub fn new(context: &'ctx Context) -> Self {
        let module = context.create_module("main");
        let builder = context.create_builder();
        let fpm = inkwell::passes::PassManager::create(());

        fpm.add_ipsccp_pass();
        fpm.add_new_gvn_pass();
        fpm.add_ind_var_simplify_pass();
        fpm.add_instruction_simplify_pass();
        fpm.add_instruction_combining_pass();

        fpm.add_constant_merge_pass();
        fpm.add_global_optimizer_pass();

        fpm.add_demote_memory_to_register_pass();
        fpm.add_merge_functions_pass();
        fpm.add_dead_arg_elimination_pass();
        fpm.add_function_attrs_pass();
        fpm.add_function_inlining_pass();
        fpm.add_tail_call_elimination_pass();

        fpm.add_licm_pass();
        fpm.add_cfg_simplification_pass();

        fpm.add_global_dce_pass();
        fpm.add_aggressive_dce_pass();
        fpm.add_loop_deletion_pass();

        Self {
            context: &context,
            module,
            builder,
            fpm,
        }
    }
}
``` 
You will see a lot of the same structs here, with the addition of the fpm, it is the optimizer!
We don't have to write it ourselves! So instead of worrying about if we should optimize stuff, just don't first and see if LLVM does it for you, if it does, then great less work for us! So always try the simple stuff first, like we will output every variable on the heap, but LLVM will promote them to registers where it works. 

```rust
    fn int_type(&self) -> inkwell::types::IntType {
        use crate::IntWidth;

        match IntWidth {
            8 => self.context.i8_type(),
            16 => self.context.i16_type(),
            32 => self.context.i32_type(),
            64 => self.context.i64_type(),
            128 => self.context.i128_type(),
            _ => panic!("Invalid int width"),
        }
    }
```
We also have this so the Int width in `lib.rs` is easier to work (this means we are restricted to these options.)
Now we can actually do some code gen:
```rust
    fn compile_libc_definitions(&mut self) {
        let i32_type = self.context.i32_type();
        let i8_type = self.context.i8_type();
        let i8_ptr_type = i8_type.ptr_type(inkwell::AddressSpace::default());

        let printf_type = i32_type.fn_type(&[i8_ptr_type.into()], true);
        self.module.add_function("printf", printf_type, None);
    }

    fn compile_int_expression(&self, expression: &ir::IntExpression) -> inkwell::values::IntValue {
        match expression {
            ir::IntExpression::Literal(int) => self.int_type().const_int(*int as u64, false),
        }
    }

    fn compile_print_statement(&self, statement: &ir::PrintStatement) {
        let printf = self.module.get_function("printf").unwrap();

        let format_string = match statement {
            ir::PrintStatement::Int(_) => "%d\n",
        };
        let format_string = self
            .builder
            .build_global_string_ptr(format_string, "format_string")
            .as_pointer_value();

        match statement {
            ir::PrintStatement::Int(int_expression) => {
                let int_value = self.compile_int_expression(int_expression);
                self.builder.build_call(
                    printf,
                    &[format_string.into(), int_value.into()],
                    "printf",
                );
            }
        }
    }

    fn compile_statement(&self, statement: &ir::Statement) {
        match statement {
            ir::Statement::Print(print_statement) => self.compile_print_statement(print_statement),
        }
    }

    pub fn compile_module(&mut self, module: &ir::Module) {
        self.compile_libc_definitions();
        // In the future we will have functions, for now put everything in main()

        let i32_type = self.context.i32_type();
        let main_type = i32_type.fn_type(&[], false);
        let main = self.module.add_function("main", main_type, None);
        let main_block = self.context.append_basic_block(main, "entry");
        self.builder.position_at_end(main_block);

        for statement in &module.0 {
            self.compile_statement(statement);
        }

        self.builder
            .build_return(Some(&i32_type.const_int(0, false)));
    }
```
We need to add the libc functions definitions we will be using, we will be using more in the future so stay tuned :P

The most complex part here is the print statement, but it should look very similar to what we did in part 1! We just do some conditional selecting of the formatting string, so the constructed call might look like `printf("%d\n", 1)`.

We can now save this, and here is a small optimization I will do! In the last post we used the text version of LLVM IR, but there is a bytecode version that will take up less space and be more efficient!

```rust
    pub fn output_to_file(&mut self, file_path: &std::path::Path, options: &CompilerOptions) {
        if !options.dont_optimize {
            self.fpm.run_on(&self.module);
        }

        self.module.write_bitcode_to_path(file_path);

        if options.output_llvm {
            self.module.print_to_stderr();
        }
    }
```

And yes we do generate the output twice if we have the debug flag set, but it is a debug flag, it doesn't really matter.
We also run optimization in this part because we already have the compiler options!

Now we just have to call this from our `build` function, but one question, in what file should we save the result? well, here the [`temp-file`](https://crates.io/crates/temp-file) crate will help us! it will allow us to create temporary files for use during compiling!

```bash
cargo add temp-file
```

then we can generate and use our temporary file
```rust
// lib.rs - build(...)
    let inkwell_context = inkwell::context::Context::create();
    let mut code_gen = code_gen::CodeGen::new(&inkwell_context);
    code_gen.compile_module(&ir);

    let llvm_ir_output_file = temp_file::empty();
    code_gen.output_to_file(llvm_ir_output_file.path(), &options);
```

We can now run this, `cargo run -- run test.viv --output-llvm`, and we should get
```
; ModuleID = 'main'
source_filename = "main"

@format_string.1 = private unnamed_addr constant [4 x i8] c"%d\0A\00", align 1

declare i32 @printf(ptr %0, ...) local_unnamed_addr

define i32 @main() local_unnamed_addr {
entry:
  %printf = tail call i32 (ptr, ...) @printf(ptr noundef nonnull @format_string.1, i32 1)
  %printf1 = tail call i32 (ptr, ...) @printf(ptr noundef nonnull @format_string.1, i32 2)
  ret i32 0
}
```

### Compiling to binary

Now we need to compile this LLVM IR down to a binary, to do this we will spawn subprocesses of `llc` and `clang`/`gcc`.

To do this we will create some helper functions!

```rust
// lib.rs
fn find_on_path(program: &str) -> Option<std::path::PathBuf> {
    let path = std::env::var_os("PATH")?;

    for dir in std::env::split_paths(&path) {
        let candidate = dir.join(program);

        if candidate.is_file() {
            return Some(candidate);
        }
    }

    None
}

fn find_any_on_path(programs: Vec<&str>) -> Option<std::path::PathBuf> {
    for program in programs {
        if let Some(path) = find_on_path(program) {
            return Some(path);
        }
    }

    None
}
```
These two functions will let us search the `PATH` env variable for the command line tools we need to invoke!

We then use these to do our 2 steps in compiling from an LLVM ir to a binary
```rust
fn compile_to_objectfile(from: &str, to: &str) -> anyhow::Result<()> {
    let clang = find_on_path("llc").ok_or(anyhow::anyhow!("Llc not found on path"))?;
    std::process::Command::new(clang)
        .args([from, "-filetype=obj", "-o", to])
        .spawn()?
        .wait()?
        .success()
        .then_some(())
        .ok_or(anyhow::anyhow!("Llc failed"))?;

    Ok(())
}

fn compile_to_binary(from: &str, to: &str) -> anyhow::Result<()> {
    let clang = find_any_on_path(vec!["clang", "gcc"])
        .ok_or(anyhow::anyhow!("Clang or gcc not found on path"))?;
    std::process::Command::new(clang)
        .args([from, "-no-pie", "-o", to])
        .spawn()?
        .wait()?
        .success()
        .then_some(())
        .ok_or(anyhow::anyhow!("Clang/gcc failed"))?;

    Ok(())
}
```
Then we can use these in the `build` function
```rust
pub fn build(
    file_name: &str,
    output_file: &str,
    options: CompilerOptions,
) -> anyhow::Result<()> {
    // ...

    let llvm_ir_output_file = temp_file::empty();
    code_gen.output_to_file(llvm_ir_output_file.path(), &options);

    let object_file = temp_file::empty();
    compile_to_objectfile(
        llvm_ir_output_file.path().to_str().unwrap(),
        object_file.path().to_str().unwrap(),
    )?;
    compile_to_binary(object_file.path().to_str().unwrap(), output_file)?;

    Ok(())
}
```

let's update our Run code to generate an output file and run it
```rust
// main.rs
    match arguments.command {
        CompilerCommand::Run { input_file } => {
            let output_file = temp_file::empty();
            build(
                &input_file,
                output_file.path().to_str().unwrap(),
                compiler_options,
            )
            .context("Building input file")?;

            let output = std::process::Command::new(output_file.path())
                .spawn()?
                .wait()?;

            std::process::exit(output.code().unwrap_or(1));
        }
    }

```

if we now just run our script, `cargo run -- run test.viv` you should see `1` and `2` being printed on the terminal! Congratulations! We now have a fully working compiler :D

## Build command

Just one last thing I want to add before we wrap up, add a `build` command, what use is a compiler if we can't save our binary? 
```rust
// main.rs

#[derive(Subcommand)]
enum CompilerCommand {
    /// Compile and run file
    Run { input_file: String },
    /// Compile file
    Build {
        input_file: String,
        output_file: String,
    },
}

// ...

    match arguments.command {
        CompilerCommand::Run { input_file } => {
            // ...
        }
        CompilerCommand::Build {
            input_file,
            output_file,
        } => {
            build(&input_file, &output_file, compiler_options).context("Building input file")?;
        }
    }
```

we can now test our new command.
```bash
cargo run -- build test.viv test 
./test
```

## Conlusion

So today we made a complete compiler, fair enough it does only support printing numbers, but my god wasn't it fun! So much learning, if you want you can go ahead and play with this, try changing the syntax, and maybe even add more features yourself? 

## Next steps

In the next post we will create the next obvious feature booleans!
... wait really? booleans? we don't even have operators!

And yhe you are right, it is a bit unusual, our first operator will be `==`, but there is a good reason. I want to start writing integration tests, and for that, we need `==`.

But we will do that next! If you have any questions feel free to leave them in the comments below. 
